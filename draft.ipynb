{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'class']\n",
      "[[1, '<=5.80', '>3.00', '<=4.35', '<=1.30', 1], [2, '<=5.80', '<=3.00', '<=4.35', '<=1.30', 1], [3, '<=5.80', '>3.00', '<=4.35', '<=1.30', 1], [4, '<=5.80', '>3.00', '<=4.35', '<=1.30', 1], [5, '<=5.80', '>3.00', '<=4.35', '<=1.30', 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "class DataFrame:\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        assert file_path is not None, 'Please inform the file path'\n",
    "        self.__read_csv(file_path)\n",
    "        \n",
    "        '''dict for each column type by column'''\n",
    "        self.__init_col_types()\n",
    "        '''list for each column index by name'''\n",
    "        self.__init_col_to_index_dict()        \n",
    "        self.shape = (len(self.values), len(self.columns))\n",
    "\n",
    "        self.factorized_cols = dict()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        key_type = type(key)\n",
    "        if key_type == int:\n",
    "            return self.values[key]\n",
    "        elif key_type == str:\n",
    "            j = self.__get_col_index_by_key(key)\n",
    "            return np.array(\n",
    "                [self.values[i][j] for i in range(self.shape[0])],\n",
    "                dtype=self.column_types[j]\n",
    "            )\n",
    "        elif key_type == tuple:\n",
    "            assert len(key) == 2, 'Invalid tuple size'\n",
    "            if key[1] < 0:\n",
    "                key = (key[0], self.shape[1] - key[1])\n",
    "            new_values = []\n",
    "            for row in self.values:\n",
    "                new_values.append([x for i, x in enumerate(row) if i >= key[0] and i < key[1]])\n",
    "            return new_values\n",
    "        else:\n",
    "            raise Exception('Invalid key type')\n",
    "\n",
    "    def __init_col_to_index_dict(self):\n",
    "        self.colum_to_index_dict = dict()\n",
    "        for i, c in enumerate(self.columns):\n",
    "            self.colum_to_index_dict[c] = i\n",
    "\n",
    "    def __init_col_types(self):\n",
    "        def get_value_type(v):\n",
    "            try:\n",
    "                int(v)\n",
    "                return int\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                float(v)\n",
    "                return float\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            return str\n",
    "\n",
    "        self.column_types = []\n",
    "        for j in range(len(self.columns)):\n",
    "            type = get_value_type(self.values[0][j])\n",
    "            self.column_types.append(type)\n",
    "            for i in range(len(self.values)):\n",
    "                self.values[i][j] = type(self.values[i][j])\n",
    "\n",
    "    def __read_csv(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        self.columns = lines[0].replace('\\n', '').split(',')\n",
    "        self.values = [l.replace('\\n', '').split(',') for l in lines[1:]]\n",
    "\n",
    "    def __get_col_index_by_key(self, key):\n",
    "        key_type = type(key)\n",
    "        if key_type == str:\n",
    "            assert key in self.columns, 'Invalid key'\n",
    "            return self.colum_to_index_dict[key]\n",
    "        elif key_type == int:\n",
    "            return key\n",
    "        else:\n",
    "            raise Exception('Invalid key type')\n",
    "\n",
    "    def __continuous_split(self, key):\n",
    "        col_i = self.__get_col_index_by_key(key)\n",
    "        assert self.column_types[col_i] == float, 'This can only be done to continuous valued columns'\n",
    "\n",
    "        values = self[self.columns[col_i]]\n",
    "        median = np.median(values)\n",
    "        median_str = '{:.2f}'.format(median)\n",
    "    \n",
    "        for i in range(self.shape[0]):\n",
    "            self.values[i][col_i] = f'<={median_str}' if self.values[i][col_i] <= median else f'>{median_str}'\n",
    "        self.column_types[col_i] = str\n",
    "\n",
    "    def categorize_continuous_values(self):\n",
    "        for i, t in enumerate(self.column_types):\n",
    "            if t == float:\n",
    "                self.__continuous_split(i)\n",
    "\n",
    "    def factorize(self, key):\n",
    "        col_i = self.__get_col_index_by_key(key)\n",
    "\n",
    "        classes = set(self[self.columns[col_i]])\n",
    "        class_dict = dict()\n",
    "        inverse_class_dict = dict()\n",
    "        for i, c in enumerate(classes):\n",
    "            class_dict[c] = i\n",
    "            inverse_class_dict[i] = c\n",
    "        self.factorized_cols[self.columns[col_i]] = inverse_class_dict\n",
    "\n",
    "        for i in range(self.shape[0]):\n",
    "            self.values[i][col_i] = class_dict[self.values[i][col_i]]\n",
    "        self.column_types[col_i] = int\n",
    "\n",
    "    def train_test_split(self, X_indexes, y_class=-1, perc=.25):\n",
    "        split_index = int(self.shape[0] * (1 - perc))\n",
    "        shuffled_data = deepcopy(self.values)\n",
    "        random.shuffle(shuffled_data)\n",
    "        \n",
    "        train, test = shuffled_data[:split_index], shuffled_data[split_index:]\n",
    "        \n",
    "        X_train = [x[X_indexes[0]:X_indexes[1]] for x in train]\n",
    "        X_test = [x[X_indexes[0]:X_indexes[1]] for x in test]\n",
    "\n",
    "        y_train = [x[y_class] for x in train]\n",
    "        y_test = [x[y_class] for x in test]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def get_values_by_cols(self, cols):\n",
    "        return [[a for i, a in enumerate(x) if i in cols] for x in self.values]\n",
    "\n",
    "\n",
    "df = DataFrame(file_path='datasets/iris.csv')\n",
    "df.factorize('class')\n",
    "df.categorize_continuous_values()\n",
    "\n",
    "print(df.columns)\n",
    "print(df.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, X, y, columns, parent=None, original_col_indexes=None):\n",
    "        if parent is None:\n",
    "            assert len(X) > 0 and len(y) > 0\n",
    "        else:\n",
    "            self.parent = parent\n",
    "\n",
    "        assert len(X) == len(y)\n",
    "        self.X, self.y = X, y\n",
    "        self.parent = parent\n",
    "        self.columns = columns\n",
    "        \n",
    "        if original_col_indexes is not None:\n",
    "            self.original_col_indexes = original_col_indexes\n",
    "        else:\n",
    "            self.original_col_indexes = list(range(len(columns)))\n",
    "\n",
    "        self.is_leaf = self.__decide_if_leaf()\n",
    "        if not self.is_leaf:\n",
    "            self.children = []\n",
    "            self.class_to_children = dict()\n",
    "            self.generate_children()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.leaf_value\n",
    "        else:\n",
    "            return self.children[self.class_to_children[x[self.deciding_col]]](x)\n",
    "\n",
    "    def __get_column_values(self, col):\n",
    "        #assert type(col) != int, f'Invalid key type: {type(col)}'\n",
    "        assert col >= 0 and col < len(self.columns), 'Invalid key value'\n",
    "        return [self.X[i][col] for i in range(len(self.X))]\n",
    "\n",
    "    def __decide_if_leaf(self):\n",
    "        if len(self.y) == 0:\n",
    "            self.leaf_value = self.parent.most_common_y()\n",
    "            return True\n",
    "        elif all([i == self.y[0] for i in self.y]):\n",
    "            self.leaf_value = self.y[0]\n",
    "            return True\n",
    "        elif len(self.columns) == 0:\n",
    "            self.leaf_value = self.parent.most_common_y()\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def __class_entropy(self, col_values):\n",
    "        value_counter = dict()\n",
    "        for v in col_values:\n",
    "            if v not in value_counter.keys():\n",
    "                value_counter[v] = 1\n",
    "            else:\n",
    "                value_counter[v] += 1\n",
    "\n",
    "        col_size = len(col_values)\n",
    "        for k in value_counter.keys():\n",
    "            value_counter[k] /= col_size\n",
    "        \n",
    "        return sum([-p * np.log2(p) for _, p in value_counter.items()])\n",
    "\n",
    "    def __drop_column(self, X, col):\n",
    "        new_X = []\n",
    "        for x in X:\n",
    "            new_X.append([elem for i, elem in enumerate(x) if i != col])\n",
    "        return new_X\n",
    "\n",
    "    def __local_index_of_original(self, target):\n",
    "        for i, original_i in enumerate(self.original_col_indexes):\n",
    "            if original_i == target:\n",
    "                return i\n",
    "        raise Exception('Index not found')\n",
    "\n",
    "    def most_common_y(self):\n",
    "        biggest_count = -1\n",
    "        most_common_y = -1\n",
    "        for y, count in np.unique(self.y, return_counts=True):\n",
    "            if count > biggest_count:\n",
    "                biggest_count = count\n",
    "                most_common_y = y\n",
    "        return most_common_y \n",
    "    \n",
    "    def entropy(self, column):\n",
    "        col_values = self.__get_column_values(column)\n",
    "        return self.__class_entropy(col_values)\n",
    "\n",
    "    def generate_children(self):\n",
    "        max_entropy_col = self.original_col_indexes[0]\n",
    "        max_entropy = self.entropy(0)\n",
    "        for i in range(len(self.columns)):\n",
    "            tmp_entropy = self.entropy(i)\n",
    "            if tmp_entropy > max_entropy:\n",
    "                max_entropy = tmp_entropy\n",
    "                max_entropy_col = self.original_col_indexes[i]\n",
    "        \n",
    "        self.deciding_col = max_entropy_col\n",
    "        local_max_entropy_index = self.__local_index_of_original(max_entropy_col)\n",
    "        \n",
    "        new_cols, new_original_col_indexes = [], []\n",
    "        for c, original_i in zip(self.columns, self.original_col_indexes):\n",
    "            if original_i != max_entropy_col:\n",
    "                new_cols.append(c)\n",
    "                new_original_col_indexes.append(original_i)\n",
    "        #new_cols, new_original_col_indexes = zip(*[(c, original_i) for c, original_i in zip(self.columns, self.original_col_indexes) if original_i != max_entropy_col])\n",
    "\n",
    "        classes = np.unique(self.__get_column_values(local_max_entropy_index))\n",
    "        for i, c in enumerate(classes):\n",
    "            new_X, new_y = [], []\n",
    "            for x, y in zip(self.X, self.y):\n",
    "                if x[local_max_entropy_index] == c:\n",
    "                    new_X.append(x)\n",
    "                    new_y.append(y)\n",
    "            #new_dataset = [(x, y) for x, y in zip(self.X, self.y) if x[local_max_entropy_index] == c]\n",
    "    \n",
    "            #new_X, new_y = zip(*new_dataset)\n",
    "            new_X = self.__drop_column(new_X, local_max_entropy_index)\n",
    "\n",
    "            self.class_to_children[c] = i\n",
    "            self.children.append(Node(new_X, new_y, new_cols, self, new_original_col_indexes))\n",
    "            \n",
    "X = df.get_values_by_cols(list(range(1, df.shape[1] - 1)))\n",
    "y = df['class']\n",
    "cols = df.columns[1:-1]\n",
    "\n",
    "root = Node(X, y, cols)\n",
    "root(X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import colorama\n",
    "from colorama import Fore, Style\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, X, y, col_names, depth=0, parent=None):\n",
    "        assert len(X) == len(y)\n",
    "        if parent is None:\n",
    "            assert len(X) > 0 and len(y) > 0\n",
    "        #if len(X) > 0:\n",
    "            #assert len(X[0]) == len(col_names)\n",
    "\n",
    "        self.X, self.y = deepcopy(X), deepcopy(y)\n",
    "        self.col_names = deepcopy(col_names)\n",
    "        self.X_shape = (len(X), len(X[0]))\n",
    "        self.depth = depth\n",
    "        self.parent = parent\n",
    "\n",
    "        self.is_leaf = self.__decide_if_leaf()\n",
    "        if not self.is_leaf:\n",
    "            self.__generate_children()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.predict(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = deepcopy(x)\n",
    "        if self.is_leaf:\n",
    "            return self.leaf_value\n",
    "        else:\n",
    "            deciding_col_value = x[self.deciding_col]\n",
    "            del x[self.deciding_col]\n",
    "\n",
    "            if deciding_col_value in self.children.keys():\n",
    "                return self.children[deciding_col_value].predict(x)\n",
    "            else:\n",
    "                return self.children[random.choice(list(self.children.keys()))].predict(x)\n",
    "\n",
    "    def most_common_y(self):\n",
    "        count_dict = dict()\n",
    "        for y_i in self.y:\n",
    "            if y_i not in count_dict.keys():\n",
    "                count_dict[y_i] = 1\n",
    "            else:\n",
    "                count_dict[y_i] += 1\n",
    "\n",
    "        biggest_count = -1\n",
    "        most_common_y = -1\n",
    "        for y, count in count_dict.items():\n",
    "            if count > biggest_count:\n",
    "                biggest_count = count\n",
    "                most_common_y = y\n",
    "        return most_common_y, biggest_count\n",
    "\n",
    "    def __get_column_values(self, col):\n",
    "        assert col >= 0 and col < len(self.X[0]), 'Invalid key value'\n",
    "        return [self.X[i][col] for i in range(len(self.X))]\n",
    "\n",
    "    def __decide_if_leaf(self):\n",
    "        if len(self.y) == 0:\n",
    "            self.leaf_value, self.leaf_counter = self.parent.most_common_y()\n",
    "            return True\n",
    "        elif all([i == self.y[0] for i in self.y]):\n",
    "            self.leaf_value = self.y[0]\n",
    "            self.leaf_counter = len(self.y)\n",
    "            return True\n",
    "        elif self.X_shape[1] == 0:\n",
    "            self.leaf_value, self.leaf_counter = self.parent.most_common_y()\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def __attribute_entropy(self, col):\n",
    "        value_counter = dict()\n",
    "        col_values = self.__get_column_values(col)\n",
    "        for v in col_values:\n",
    "            if v not in value_counter.keys():\n",
    "                value_counter[v] = 1\n",
    "            else:\n",
    "                value_counter[v] += 1\n",
    "\n",
    "        col_size = len(col_values)\n",
    "        for k in value_counter.keys():\n",
    "            value_counter[k] /= col_size\n",
    "\n",
    "        return sum([(-1) * p * np.log2(p) for _, p in value_counter.items()])\n",
    "\n",
    "    def __decide_most_important_attribute(self):\n",
    "        assert self.X_shape[0] > 0\n",
    "        \n",
    "        highest_entropy = self.__attribute_entropy(0)\n",
    "        highest_entropy_col = 0\n",
    "        for j in range(1, self.X_shape[1]):\n",
    "            tmp_entropy = self.__attribute_entropy(j)\n",
    "            if tmp_entropy > highest_entropy:\n",
    "                highest_entropy = tmp_entropy\n",
    "                highest_entropy_col = j\n",
    "        \n",
    "        self.deciding_col = highest_entropy_col\n",
    "\n",
    "    def __get_dropped_col_dataset(self, X, col):\n",
    "        for x in X:\n",
    "            del x[col]\n",
    "        return X\n",
    "\n",
    "    def __split_dataset_by_classes(self, X, y, deciding_col):\n",
    "        classes = set(self.__get_column_values(deciding_col))\n",
    "        class_to_dataset = dict()\n",
    "        for c in classes:\n",
    "            new_X, new_y = zip(*[(x, y_i,) for x, y_i in zip(X, y) if x[deciding_col] == c])\n",
    "            class_to_dataset[c] = (new_X, new_y,)\n",
    "        return class_to_dataset\n",
    "\n",
    "    def __generate_children(self):\n",
    "        self.__decide_most_important_attribute()\n",
    "        self.children = dict()\n",
    "\n",
    "        new_col_names = [c for i, c in enumerate(self.col_names) if i != self.deciding_col]\n",
    "\n",
    "        class_to_dataset = self.__split_dataset_by_classes(self.X, self.y, self.deciding_col)\n",
    "        for k, (new_X, new_y) in class_to_dataset.items():\n",
    "            new_X = self.__get_dropped_col_dataset(new_X, self.deciding_col)\n",
    "            self.children[k] = Node(new_X, new_y, new_col_names, self.depth+1, self)\n",
    "\n",
    "    def print(self, inverser):\n",
    "        if self.is_leaf:\n",
    "            print(Fore.CYAN + f'{inverser[self.leaf_value]} ({self.leaf_counter})')\n",
    "            return\n",
    "\n",
    "        tabs = ''\n",
    "        for _ in range(self.depth * 2):\n",
    "            tabs += '    '\n",
    "        \n",
    "        attribute = self.col_names[self.deciding_col]\n",
    "        print(Fore.WHITE + f'{tabs}<{attribute}>')\n",
    "        \n",
    "        for k, child in self.children.items():\n",
    "            print(Fore.MAGENTA + f'{tabs}    {k}:', end=('\\n' if not child.is_leaf else ' '))\n",
    "            child.print(inverser)\n",
    "\n",
    "        \n",
    "X = df.get_values_by_cols(list(range(1, df.shape[1] - 1)))\n",
    "y = df['class']\n",
    "cols = df.columns[1:-1]\n",
    "\n",
    "root = Node(X, y, cols)\n",
    "x = X[3]\n",
    "res = root(x)\n",
    "print(res)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.68%\n"
     ]
    }
   ],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, X, y, columns, inverse_class_dict):\n",
    "        self.inverse_class_dict = inverse_class_dict\n",
    "        self.root = Node(X, y, columns)\n",
    "        #colorama.init()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.predict(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        prediction = self.root(x)\n",
    "        return self.inverse_class_dict[prediction]\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        res = 0\n",
    "        for x, y_i in zip(X, y):\n",
    "            res += int(self(x) == self.inverse_class_dict[y_i])\n",
    "        return res / len(y)\n",
    "\n",
    "    def print(self):\n",
    "        self.root.print(self.inverse_class_dict)\n",
    "        print(Style.RESET_ALL)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = df.train_test_split((1, -1), perc=.25)\n",
    "\n",
    "inverser = df.factorized_cols['class']\n",
    "dt = DecisionTree(X_train, y_train, cols, inverser)\n",
    "\n",
    "print(f'{dt.evaluate(X_test, y_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m<petallength>\n",
      "\u001b[35m    <=4.35:\n",
      "\u001b[37m        <sepalwidth>\n",
      "\u001b[35m            <=3.00:\n",
      "\u001b[37m                <sepallength>\n",
      "\u001b[35m                    >5.80: \u001b[36mIris-versicolor (4)\n",
      "\u001b[35m                    <=5.80:\n",
      "\u001b[37m                        <petalwidth>\n",
      "\u001b[35m                            <=1.30: \u001b[36mIris-versicolor (16)\n",
      "\u001b[35m                            >1.30: \u001b[36mIris-versicolor (1)\n",
      "\u001b[35m            >3.00: \u001b[36mIris-setosa (30)\n",
      "\u001b[35m    >4.35:\n",
      "\u001b[37m        <sepalwidth>\n",
      "\u001b[35m            <=3.00:\n",
      "\u001b[37m                <sepallength>\n",
      "\u001b[35m                    >5.80:\n",
      "\u001b[37m                        <petalwidth>\n",
      "\u001b[35m                            >1.30: \u001b[36mIris-virginica (21)\n",
      "\u001b[35m                            <=1.30: \u001b[36mIris-versicolor (3)\n",
      "\u001b[35m                    <=5.80:\n",
      "\u001b[37m                        <petalwidth>\n",
      "\u001b[35m                            >1.30: \u001b[36mIris-versicolor (4)\n",
      "\u001b[35m                            <=1.30: \u001b[36mIris-versicolor (2)\n",
      "\u001b[35m            >3.00:\n",
      "\u001b[37m                <sepallength>\n",
      "\u001b[35m                    >5.80:\n",
      "\u001b[37m                        <petalwidth>\n",
      "\u001b[35m                            >1.30: \u001b[36mIris-virginica (12)\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dt.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Weather', 'Temp', 'Humidity', 'Windy', 'Play']\n",
      "[[1, 'sunny', 85, 85, 'FALSE', 0], [2, 'sunny', 80, 90, 'TRUE', 0], [3, 'overcast', 83, 86, 'FALSE', 1], [4, 'rainy', 70, 96, 'FALSE', 1], [5, 'rainy', 68, 80, 'FALSE', 1]]\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame(file_path='datasets/weather.csv')\n",
    "df.factorize('Play')\n",
    "df.categorize_continuous_values()\n",
    "\n",
    "print(df.columns)\n",
    "print(df.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = df.train_test_split((1, -1), perc=.4)\n",
    "\n",
    "inverser = df.factorized_cols['Play']\n",
    "dt = DecisionTree(X_train, y_train, cols, inverser)\n",
    "\n",
    "print(f'{dt.evaluate(X_test, y_test) * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "521bd52f7db69f83952e45c69a41cc5a9312142da056b7c563e70a654200e62d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
